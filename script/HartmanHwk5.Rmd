---
title: "Improving Term Deposit Client Base"
author: "Lauren Hartman"
date: "4/23/2017"
output: html_document
---
# The Scenario
The President and Vice President of a fictitious bank, Hometown Bank, want me to help boost their understanding and positioning in the term deposit market. They gave me a dataset containing demographic information about their clients. Of interest to the President and Vice President is whether clients have or have not opened term deposits. Given this dataset, can customers' chance of opening term deposits be predicted, thus increasing the bank's market share in the term deposit market? If so, what recommendations can be made for increasing term deposits?

# The Data
The dataset contains 40,000 records.
```{r}
Term_Deposit <- read.csv("/Users/laurenhartman/Documents/Rockhurst/Applied Data Mining/Improving Term Deposit Client Base/Bank_Full.csv")
```

# Building a Decision Tree 
Before the decision tree can be built, the dataset needs to be divided into a training and a test set. A training set is used to teach a model how to predict a desired outcome. A test set is then used to determine how well a model makes the desired predictions. 80% of the records will go into the training set and 20% of the records will go into the test set. The code will split the dataset randomly, which prevents the records in the test set from sharing a common feature with most other records within the test set. For example, a model will not be able to learn to predict whether an entrepreneur will subscribe to a term deposit or not if all the entrepreneurs are in the test set. When a seed value is set, the randomization process will follow a sequence which can be replicated. This means a similiar outcome will be reached everytime the model is used.

A decision tree determines the relationships among the characteristics and the probability of a client subscribing to a term deposit. A decision tree model's output resembles an upside down tree. In the dataset, less than 1% of the clients opened a term deposit. As a result, the decision tree will have far more opportunities to learn when a client will not subscribe to a term deposit than when a client will subscribe t a term deposit. However, this conflicts with my goal of determining what characteristics are indicators of a client opening a term deposit. The caret package forces the decision tree to spend more effort on correctly predicting when a client will open a term deposit. 
```{r}
library(caret)
library(rpart)

set.seed(123)
trainIndex <- createDataPartition(Term_Deposit$y..category, p = .8,list = FALSE,times = 1)
Term_Deposit_train_caret <- Term_Deposit[ trainIndex,]
Term_Deposit_test_caret <- Term_Deposit[ -trainIndex,]

Term_Deposit_rpart_caret <- rpart(y..category~., method="class", parms = list(split="gini"), data=Term_Deposit_train_caret)

plot(Term_Deposit_rpart_caret, uniform=TRUE, main="Classification Tree for Term Deposit Clients")
text(Term_Deposit_rpart_caret, use.n=TRUE, all=TRUE, cex=0.8)
```

The code below will format the above visualization, making it easier to read and understand.
```{r}
library(rpart.plot)
rpart.plot(Term_Deposit_rpart_caret, type=1, extra=103)
```
According to the decision tree above, duration number and poutcome category are the greatest influencers of a client's chance of subscribing to a term deposit. Duration number refers to the length of last contact with a customer, in seconds. Poutcome category refers to whether the last campaign a client was a target of was a sucessful, failure, or undetermined.

A confusion matrix is a table which list performance metrics of a model. Of importance currently is sensitivity, which refers to the model's ability to correctly predict when a client opened a term deposit.
```{r}
actual <- Term_Deposit_test_caret$y..category
predicted <- predict(Term_Deposit_rpart_caret, Term_Deposit_test_caret, type="class")
results.matrix <- confusionMatrix(predicted, actual, positive="yes")
print(results.matrix)
```
This decision tree correctly predicts when a client subscribes to a term deposit 36% of the time. I want a model with a higher sensitivity rate. Before moving on to a different model, however, I wish to evaluate the accuracy of this model. Accuracy is the model's ability to correctly determine the outcome.

# Evaluating the Performance of the Decision Tree
The best way to evaluate the performanc of a model is to calculate the true error rate. The true error rate is obtained by comparing the model's predictions against the actual outcomes in the entire population. However, working with the entire population is not feasible. One or more samples from the population are used instead.

Resampling simulates the conditions necessary in calculating the true error rate. To do so, samples are repeatedly drawn from the sample(s) present. Resampling is used to compare the performance of competing models.

Bootstrapping is a resampling technique which obtains distinct datasets by repeatedly sampling observations from the original dataset while replacing the sampled observations. Consequently, some observations may appear more than once in a given boostrapped dataset while other observations may not appear at all. The below code will use 10 bootstrapped samples.
```{r}
cvCtrl <- trainControl(method="boot", number=10) 
set.seed(123)
Term_Deposit_bootstrap<-train(y..category~., data=Term_Deposit_train_caret, method="rpart", metric="Accuracy", trControl=cvCtrl)
Term_Deposit_bootstrap
```
The complexity parameter(cp) is used to calculate  the optimal number of "branches" in the decision tree. If a branch does not increase R^2 by cp, then the branch will not be created. R^2 is amount of variability explained by the model. According to the code above, a higher accuracy is not obtainable when using a decision tree on this dataset. As a result, it would be difficult to increase sensitivity without moving on to a different model.

# Building More Sensitive Models
A decision tree suffers from high variance, and an entirely different decision tree is created everytime the model is ran. A consistent model is a more reliable model. A model with low variance will result in similar outcomes if the model is applied repeatedly to distinct datasets. Two ensemble models will be used next: a bagging model and a random forest model. An ensemble model is composed of many models, and in these two cases, of many decision trees. Ideally, the different decision trees will compensate for one another's weaknesses, resulting in a higher sensitivity and accuracy rate. The downside of ensemble models is interpretability is lost.

# The Bagging Model
The bagging model considers all the predictors before making a new branch. I will stay with the default number of trees, which is 500 trees.
```{r}
library(randomForest)

set.seed(123)

Term_Deposit.bag <- randomForest(y..category~., mtry=16, data=Term_Deposit_train_caret, na.action=na.omit, importance=TRUE)
```

# Out of Bag Error
Next, I would like to see the probability of the bagging model not accurately determining an outcome.
```{r}
print(Term_Deposit.bag)
```
The bagging model will make an incorrect determination one out of ten times.

# Determining the Important Predictors in the Bagging Model
To determine the importance of an predictor, I will look at which predictors have the largest average decrease in accuracy when excluded.
```{r}
importance(Term_Deposit.bag, type=1)
```
Taking out the duration number, month category, and day number would have the greatest impact on the model's accuracy. The month category refers to the month in which the client was last contacted. Day number refers to the day in which the client was last contacted.

Now to see how much accuracy and sensitivity has increased.
```{r}
actual <- Term_Deposit_test_caret$y..category 
Term_Deposit_predicted <- predict(Term_Deposit.bag, newdata=Term_Deposit_test_caret, type="class") 
Term_Deposit_results.matrix.bag <- confusionMatrix(Term_Deposit_predicted, actual, positive="yes") 
print(Term_Deposit_results.matrix.bag)
```
Accuracy has increase minimally. However, sensitivity has improved by approximately seventeen percent.

# The Random Forest Model
A random forest model considers only a subset of the predictors before creating a new branch. This means branch creation is not dominated by one or a few strong predictors. As a result, the impact of weaker predictors are more utilized.  When the resulting trees are averaged, more reliable outcomes are obtained since the decision trees are not dominated by the strong predictors. I will limit the number of predictors considered before each branch to four. Once again, I will use the default of 500 trees.
```{r}
set.seed(123)
Term_Deposit.RForest <- randomForest(y..category ~.,data=Term_Deposit_train_caret, mtry=4, ntree=500,na.action = na.omit, importance=TRUE)
print(Term_Deposit.RForest)
```
The error rate is less than .5% percent lower than the error rate for the bagging model. The random forest model will incorrectly predict an outcome roughly once out of ten times.

```{r}
importance(Term_Deposit.RForest, type=1)
```
According to the random forest model, taking out duration number would have the greatest negative impact on accuracy, followed by the month category predictor.

```{r}
actual <- Term_Deposit_test_caret$y..category
Term_Deposit_predicted <- predict(Term_Deposit.RForest, newdata=Term_Deposit_test_caret, type="class") 
Term_Deposit_results.matrix.rf <- confusionMatrix(Term_Deposit_predicted, actual, positive="yes") 
print(Term_Deposit_results.matrix.rf)
```
Accuracy is roughly the same in comparison to the accuracy rates for the decision tree model and the bagging model.
Even though sensitivity has now decreased by approximately four percent, more practical solutions can be formed to address client subscription rate for term deposits. Forming marketing campaigns based on four client characteristics is easier and less expensive than forming marketing campaigns based on sixteen client characteristics.

# Validating the Ensemble Models by Using the ROC Curve
The receiver operating characteristics (ROC) curve displays the true positive rate (sensitivity) against the false positive rate (1-specificity). Accuracy of the model is determined by how close the curve hugs the left hand border and then the top left border of the ROC graph. The [,2] present in the third line of the code tells the code to consider the accuracy of the predictions made for clients who did open a term deposit. The acronyms "tpr" and "fpr" stand for true positive rate and false positive rate, respectively. Below is the ROC Curve for the bagging model.
```{r}
library(ROCR)
Term_Deposit.bag_predict_prob<-predict(Term_Deposit.bag, type="prob", Term_Deposit_test_caret)
Term_Deposit.pred = prediction(Term_Deposit.bag_predict_prob[,2],Term_Deposit_test_caret$y..category)
Term_Deposit.bag.perf = performance(Term_Deposit.pred,"tpr","fpr") 
plot(Term_Deposit.bag.perf ,main="ROC Curve for Bagging Model",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
```

I will also use the ROC Curve to evaluate the random forest model.
```{r}
Term_Deposit.RForest_predict_prob<-predict(Term_Deposit.RForest, type="prob", Term_Deposit_test_caret)
Term_Deposit.pred = prediction(Term_Deposit.RForest_predict_prob[,2],Term_Deposit_test_caret$y..category)
Term_Deposit.RForest.perf = performance(Term_Deposit.pred,"tpr","fpr") 
plot(Term_Deposit.RForest.perf ,main="ROC Curve for Random Forest Model",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
```
According to the ROC Curve graphs, the bagging and random forest models have good overall accuracy. Also, the more predictors the models use, the more likely the model will accurately predict those who do open a term deposit. As more predictors are used, less people will be predicted to open a term deposit when they actually do not.

# Suggestions to the President and Vice President
Based on the models above, the most important predictors of client term deposit subscription rate are duration number, poutcome category, month category, and day number. However, further research would need to be conducted in order to determine which months and which days are the most influential, which may not be beneficial or actionable. I suspicion poutcome category influences the month category and the day number.

Even though using these two predictors gives only a 36% chance of finding clients who will subscribe to a term deposit, do so is easier and cheaper than using more than two predictors. Fortunately, not much risk is involved if a customer does not open a term deposit.

I would recommend having call representatives take time to explain the benefits of a term deposit to clients and to persuade them into opening a term deposit. I would also recommend investing in good marketing campaigns since they do influence client behavior. Additional and/or more quality employee training may be needed to obtain the most benefit from the phone calls made and from the marketing campaigns implemented.  

